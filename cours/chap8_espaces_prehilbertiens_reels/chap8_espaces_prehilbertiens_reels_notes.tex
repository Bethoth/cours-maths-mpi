\chapter{Espaces préhilbertiens réels}

\minitoc

Dans tout ce chapitre, \(E\) désigne un \(\R\)-espace vectoriel.

\section{Généralités}

\subsection{Produit scalaire}

\begin{defi}
On appelle produit scalaire sur \(E\) toute application \(\phi\) de \(E^2\) dans \(\R\) qui est

\begin{itemize}
    \item bilinéaire (linéaire par rapport à chacune de ses deux variables) \\
    \item symétrique : \(\quantifs{\tpt\paren{x,y}\in E^2}\phi\paren{x,y}=\phi\paren{y,x}\) \\
    \item définie-positive : \(\quantifs{\tpt x\in E}\phi\paren{x,x}\geq0\) et \(\phi\paren{x,x}=0\ssi x=0\).
\end{itemize}
\end{defi}

\begin{rem}
Pour montrer que \(\phi\) est un produit scalaire, on montre en général d'abord que \(\phi\) est symétrique, puis qu'elle est linéaire à gauche, la linéarité à droite découlant alors de la symétrie.
\end{rem}

\begin{defi}
Quand \(E\) est muni d'un produit scalaire, on dit que \(E\) est un espace préhilbertien. Quand, de plus, \(E\) est de dimension finie, on dit que \(E\) est un espace euclidien.

En général, on note \(\ps{}{}\) les produits scalaires.
\end{defi}

\subsection{Exemples fondamentaux}

\begin{enumerate}
    \item Le produit scalaire de la géométrie vérifie toutes ces propriétés. \\
    \item Si \(E=\R^n\), soit \(x=\paren{x_1,\dots,x_n}\) et \(y=\paren{y_1,\dots,y_n}\), on pose \(\phi\paren{x,y}=\sum_{i=1}^nx_iy_i\) : \(\phi\) est appelé le produit scalaire canonique sur \(\R^n\). \\
    \item Plus généralement, si \(E\) est un \(\R\)-espace vectoriel de dimension \(n\), alors à toute base \(\fami{B}\) de \(E\), on peut associer un produit scalaire : si \(x\) et \(y\) sont deux vecteurs de coordonnées \(X=\tcoords{x_1}{\vdots}{x_n}_{\fami{B}}\) et \(Y=\tcoords{y_1}{\vdots}{y_n}_{\fami{B}}\), on pose \(\phi\paren{x,y}=\sum_{i=1}^nx_iy_i\). L'expression matricielle du produit scalaire est alors \(\phi\paren{x,y}=\trans{X}Y\). \\
    \item Si \(a,b\) sont deux réels tels que \(a<b\), \(I=\intervii{a}{b}\) et \(E=\ensclasse{0}{I}{\R}\), alors pour \(f,g\) deux éléments de \(E\), on pose \(\phi\paren{f,g}=\int_a^bfg\) : \(\phi\) est un produit scalaire sur \(E\). \\
    \item Si \(I\) est un intervalle et \(E=\ensclasse{0}{I}{\R}\inter\integ{2}{I}{\R}\), ensemble des fonctions \(f\) à valeurs réelles, continues sur \(I\) et telles que \(f^2\) soit intégrables sur \(I\), alors pour \(f,g\) deux éléments de \(E\), on pose \(\phi\paren{f,g}=\int_Ifg\) : \(\phi\) est un produit scalaire sur \(E\). \\
    \item Dans \(\M{n}[\R]\), l'application \(\paren{A,B}\mapsto\tr\paren{\trans{A}B}\) est un produit scalaire, c'est même le produit scalaire canonique.
\end{enumerate}

\begin{dem}[5]
Montrons que si \(f,g\in\integ{2}{I}{\R}\) alors \(fg\in\integ{1}{I}{\R}\).

Pour tout \(\paren{a,b}\in\R^2\), on a \(\abs{ab}\leq\dfrac{a^2+b^2}{2}\).

Donc pour \(x\in I\), on a \(0\leq\abs{f\paren{x}g\paren{x}}\leq\dfrac{f^2\paren{x}+g^2\paren{x}}{2}\).

Or \(f^2\) et \(g^2\) sont intégrables sur \(I\) donc par comparaison de fonctions positives, \(\abs{fg}\) est intégrable sur \(I\) et donc \(fg\) est intégrable sur \(I\).

La fonction \(\phi:\paren{f,g}\mapsto\int_Ifg\) est donc bien définie sur \(E^2\).

La symétrie et la bilinéarité de \(\phi\) sont évidentes.

Pour tout \(f\in E\), \(\phi\paren{f,f}=\int_If^2\geq0\) et comme \(f^2\) est positive et continue sur \(I\), on a \[\begin{aligned}
\int_If^2=0&\ssi f^2=0 \\
&\ssi f=0.
\end{aligned}\]

Donc \(\phi\) est un produit scalaire sur \(E\).
\end{dem}

\begin{dem}[6]
Pour \(\paren{A,B}\in\M{n}[\R]^2\), on a \[\tr\paren{\trans{B}A}=\tr\paren{\trans{\paren{\trans{A}B}}}=\tr\paren{\trans{A}B}\] donc on a la symétrie.

La bilinéarité est évidente par linéarité de la trace et de la transposition et par la bilinéarité du produit matriciel.

Pour \(A\in\M{n}[\R]\), on a \(\tr\paren{\trans{A}A}=\sum_{1\leq i,j\leq n}a_{i,j}\) donc il est clair que \(\tr\paren{\trans{A}A}=0\ssi A=0_n\).
\end{dem}

\subsection{Norme euclidienne}

\begin{defi}
Soit \(E\) un espace préhilbertien. On note \(\ps{}{}\) le produit scalaire sur \(E\).

On appelle norme euclidienne assoicée au produit scalaire l'application de \(E\) dans \(\Rp\) définie par \[\quantifs{\forall x\in E}\norme{x}=\sqrt{\ps{x}{x}}.\]
\end{defi}

\begin{rem}
Cette définition a bien un sens, car d'après les propriétés d'un produit scalaire, \(\quantifs{\tpt x\in E}\ps{x}{x}\geq0\) donc \(\sqrt{\ps{x}{x}}\) existe.
\end{rem}

On vérifie alors les résultats suivants, inspirés par la géométrie habituelle dans un triangle ou un parallélogramme.

\begin{prop}
Avec les mêmes notations, pour tout \(\paren{x,y}\in E^2\),

\begin{itemize}
    \item \(\norme{x+y}^2=\norme{x}^2+\norme{y}^2+2\ps{x}{y}\) (égalité d'Al-Kashi) \\
    \item \(\norme{x-y}^2=\norme{x}^2+\norme{y}^2-2\ps{x}{y}\) (égalité d'Al-Kashi) \\
    \item \(\norme{x+y}^2+\norme{x-y}^2=2\norme{x}^2+2\norme{y}^2\) (identité du parallélogramme) \\
    \item \(\norme{x+y}^2-\norme{x-y}^2=4\ps{x}{y}\) (identité de polarisation).
\end{itemize}
\end{prop}

Et encore

\begin{prop}
Avec les mêmes notations,

\begin{itemize}
    \item \(\abs{\ps{x}{y}}\leq\norme{x}\norme{y}\) (inégalité de Cauchy-Schwarz) \\
    \item \(\norme{x+y}\leq\norme{x}+\norme{y}\) (inégalité triangulaire) \\
    \item \(\quantifs{\tpt\lambda\in\R}\norme{\lambda x}=\abs{\lambda}\norme{x}\) \\
    \item \(\norme{x}=0\ssi x=0\).
\end{itemize}
\end{prop}

\begin{rem}
Il y a égalité dans l'inégalité de Cauchy-Schwarz ssi \(x\) et \(y\) sont colinéaires.

Il y a égalité dans l'inégalité triangulaire ssi \(x\) et \(y\) sont colinéaires de même sens.
\end{rem}

\begin{dem}[Inégalité de Cauchy-Schwarz]
Soit \(\paren{x,y}\in E^2\).

Si l'un des deux vecteurs est nul, l'inégalité est vraie.

Supposons \(x\not=0\) et \(y\not=0\).

On pose \(\fonction{p}{\R}{\R}{t}{\norme{tx+y}^2}\)

\(p\) est à valeurs positives et, pour \(t\in\R\), on a \[\begin{aligned}
p\paren{t}&=\norme{tx}^2+\norme{y}^2+2\ps{tx}{y} \\
&=t^2\ps{x}{x}+\norme{y}^2+2t\ps{x}{y}.
\end{aligned}\]

Or \(\ps{x}{x}>0\) car \(x\not=0\).

Donc \(p\) est un polynôme du second degré de signe constant, donc son discriminant est négatif ou nul, \ie \[\paren{2\ps{x}{y}}^2-4\norme{x}^2\norme{y}^2\leq0.\]

Donc \(\abs{\ps{x}{y}}\leq\norme{x}\norme{y}\).

Il y a égalité ssi le trinôme \(p\) possède une unique racine réelle \(t_0\).

Dans ce cas, \(p\paren{t_0}=0=\norme{t_0x+y}^2=\ps{t_0x+y}{t_0x+y}\).

Par définie-positivité de \(\ps{}{}\), \(t_0x+y=0\) donc \(y=-t_0x\) donc \(x\) et \(y\) sont colinéaires.

Et réciproquement.
\end{dem}

\begin{dem}[Inégalité triangulaire]
Pour \(\paren{x,y}\in E^2\), on a \[\begin{WithArrows}
\norme{x+y}\leq\norme{x}+\norme{y}&\ssi\norme{x+y}^2\leq\norme{x}^2+\norme{y}^2+2\norme{x}\norme{y} \Arrow{Al-Kashi} \\
&\ssi\norme{x}^2+\norme{y}^2+2\ps{x}{y}\leq\norme{x}^2+\norme{y}^2+2\norme{x}\norme{y} \\
&\ssi\ps{x}{y}\leq\norme{x}\norme{y} \\
&\phantom{\ssi}\text{ce qui est vrai d'après l'inégalité de Cauchy-Schwarz.}
\end{WithArrows}\]

Il y a égalité ssi \(\ps{x}{y}=\norme{x}\norme{y}\), ce qui implique le cas d'égalité de l'inégalité de Cauchy-Schwarz, donc \(x\) et \(y\) sont colinéaires.

Or \(\ps{x}{y}=\norme{x}\norme{y}\geq0\) donc \(x\) et \(y\) sont positivement colinéaires.

Et réciproquement.
\end{dem}

On dit qu'un vecteur de \(E\) est unitaire (ou normalisé) si sa norme vaut \(1\). À tout vecteur \(x\in E\excluant\accol{0}\), on associe deux vecteurs unitaires : \(\dfrac{x}{\norme{x}}\) et \(-\dfrac{x}{\norme{x}}\).

\begin{exo}
Soit \(\paren{a_1,\dots,a_n,b_1,\dots,b_n}\in\R^{2n}\).

Donnez une inégalité liant \(\sum_{k=1}^na_kb_k\), \(\sum_{k=1}^na_k^2\) et \(\sum_{k=1}^nb_k^2\).
\end{exo}

\begin{corr}
On pose \(a=\paren{a_1,\dots,a_n},b=\paren{b_1,\dots,b_n}\in\R^n\).

On note \(\ps{}{}\) le produit scalaire canonique sur \(\R^n\).

D'après l'inégalité de Cauchy-Schwarz, on a \(\abs{\ps{a}{b}}\leq\norme{a}\norme{b}\) donc \[\abs{\sum_{i=1}^na_ib_i}\leq\sqrt{\sum_{i=1}^na_i^2\sum_{i=1}^nb_i^2}.\]
\end{corr}

\begin{exo}
Soit \(f\in\ensclasse{0}{\intervii{a}{b}}{\Rps}\). Montrez que \[\paren{b-a}^2\leq\paren{\int_a^bf}\paren{\int_a^b\dfrac{1}{f}}.\]
\end{exo}

\begin{corr}
On pose \(\fonction{\ps{}{}}{\ensclasse{0}{\intervii{a}{b}}{\Rps}^2}{\R}{\paren{f,g}}{\int_a^bfg}\)

D'après l'inégalité de Cauchy-Schwarz, on a \[\begin{aligned}
\abs{\ps{\sqrt{f}}{\sqrt{\dfrac{1}{f}}}}&\leq\norme{\sqrt{f}}\norme{\sqrt{\dfrac{1}{f}}} \\
\abs{b-a}&\leq\sqrt{\int_a^bf}\sqrt{\int_a^b\dfrac{1}{f}} \\
\paren{b-a}^2&\leq\paren{\int_a^bf}\paren{\int_a^b\dfrac{1}{f}}.
\end{aligned}\]
\end{corr}

\subsection{Vecteurs orthogonaux}

\begin{defi}
Soit \(E\) un espace préhilbertien. On note \(\ps{}{}\) le produit scalaire sur \(E\).

On dit que deux vecteurs \(x,y\) sont orthogonaux (pour ce produit scalaire) quand \(\ps{x}{y}=0\).

On peut alors noter \(x\perp y\) pour signifier que \(x\) et \(y\) sont orthogonaux.

Plus généralement, si \(x_1,\dots,x_n\) sont \(n\) vecteurs de \(E\), on dit que la famille \(\paren{x_1,\dots,x_n}\) est une famille orthogonale quand \[\quantifs{\tpt\paren{i,j}\in\interventierii{1}{n}^2\text{ tel que }i\not=j}\ps{x_i}{x_j}=0.\]
\end{defi}

On retrouve alors le célèbre théorème de Pythagore.

\begin{prop}
Avec les mêmes notations, \[x\perp y\ssi\norme{x+y}^2=\norme{x}^2+\norme{y}^2.\]
\end{prop}

\begin{exo}
Soient \(E\) un \(\R\)-espace vectoriel de dimension au moins \(2\) et \(u,v\) deux vecteurs non-colinéaires de \(E\).

Montrez qu'il existe un produit scalaire sur \(E\) pour lequel \(u\) et \(v\) sont orthogonaux.
\end{exo}

\begin{corr}
On pose \(n\geq2\) la dimension de \(E\).

Comme \(u\) et \(v\) ne sont pas colinéaires, \(\paren{u,v}\) est libre.

Donc d'après le théorème de la base incomplète, il existe une base \(\paren{u,v,e_3,\dots,e_n}\) de \(E\).

En posant \(\phi\) le produit scalaire associé à cette base, on a \[\phi\paren{u,v}=1\times0+0\times1+0\times0+\dots+0\times0=0.\]

Donc \(u\perp v\) pour le produit scalaire \(\phi\).
\end{corr}

\section{Bases orthonormées}

\subsection{Familles orthonormées}

\begin{defi}
Soit \(E\) un espace préhilbertien.

Une famille de vecteurs de \(E\) est dite orthonormée (ou orthonormale) quand elle est orthogonale et ses vecteurs sont unitaires.
\end{defi}

\begin{prop}
Une famille orthogonale sans vecteur nul est libre. En particulier, une famille orthonormée est libre.

Une famille orthonormée génératrice de \(E\) est donc une base orthonormée de \(E\).
\end{prop}

\begin{dem}
Soit \(\paren{v_1,\dots,v_p}\in E^p\) une famille orthogonale sans vecteur nul.

Soit \(\paren{\lambda_1,\dots,\lambda_p}\in\R^p\) tel que \(\lambda_1v_1+\dots+\lambda_pv_p=0\).

Soit \(j\in\interventierii{1}{p}\).

On a \(\ps{\lambda_1v_1+\dots+\lambda_pv_p}{v_j}=\ps{0}{v_j}=0\), or \[\begin{aligned}
\ps{\lambda_1v_1+\dots+\lambda_pv_p}{v_j}&=\lambda_1\ps{v_1}{v_j}+\dots+\lambda_p\ps{v_p}{v_j} \\
&=\lambda_j\ps{v_j}{v_j}.
\end{aligned}\]

Or \(v_j\not=0\) donc \(\ps{v_j}{v_j}\not=0\) donc \(\lambda_j=0\).

Donc \(\lambda_1=\dots=\lambda_p=0\).

Donc \(\paren{v_1,\dots,v_p}\) est libre.
\end{dem}

\begin{exo}
Généralisez l'exercice précédent.
\end{exo}

\begin{corr}
Pour toute famille libre, il existe un produit scalaire tel que cette famille soit orthogonale.
\end{corr}

\subsection{Existence de bases orthonormées}

\begin{theo}
Soit \(E\) un espace euclidien.

Il existe dans \(E\) des bases orthonormées.

De plus, pour toute base \(\paren{v_1,\dots,v_n}\) de \(E\), il existe une base orthonormée \(\paren{e_1,\dots,e_n}\) de \(E\) telle que \[\quantifs{\tpt k\in\interventierii{1}{n}}\Vect{v_1,\dots,v_k}=\Vect{e_1,\dots,e_k}.\]
\end{theo}

La démonstration repose sur l'algorithme d'orthogonalisation/orthonormalisation de Schmidt.

\begin{dem}
Soit \(\paren{v_1,\dots,v_n}\) une base de \(E\).

\begin{enumerate}
    \item On pose \(u_1=v_1\). \\
    \item On choisit \(u_2=v_2-\lambda_1u_1\) où \(\lambda_1\) est bien choisi pour que \[\begin{aligned}
        u_1\perp u_2&\text{ \ie }\ps{u_1}{u_2}=0 \\
        &\text{ \ie }\ps{u_1}{v_2-\lambda_1u_1}=0 \\
        &\text{ \ie }\ps{u_1}{v_2}-\lambda_1\ps{u_1}{u_1}=0 \\
        &\text{ \ie }\lambda_1=\dfrac{\ps{u_1}{v_2}}{\ps{u_1}{u_1}}.
    \end{aligned}\]
\end{enumerate}

Par suite, si on a construit \(\paren{u_1,\dots,u_k}\) une famille orthogonale telle que \\ \(\Vect{u_1,\dots,u_k}=\Vect{v_1,\dots,v_k}\) :

On pose \(u_{k+1}=v_{k+1}-\alpha_1u_1-\alpha_2u_2-\dots-\alpha_ku_k\) où \(\alpha_1,\dots,\alpha_k\) sont bien choisis pour obtenir \(u_{k+1}\perp u_i\) pour \(i\in\interventierii{1}{k}\).

Alors \[\begin{aligned}
\ps{u_{k+1}}{u_i}&=\ps{v_{k+1}}{u_i}-\sum_{j=1}^k\alpha_j\ps{u_j}{u_i} \\
&=\ps{v_{k+1}}{u_i}-\alpha_i\ps{u_i}{u_i}.
\end{aligned}\]

Donc \(\alpha_i=\dfrac{\ps{v_{k+1}}{u_i}}{\ps{u_i}{u_i}}\).

\(u_{k+1}\) ainsi construit est orthogonal à \(u_1,\dots,u_k\) donc \(\paren{u_1,\dots,u_{k+1}}\) est orthogonale \\ et \(u_{k+1}\in\Vect{u_{k+1},u_1,\dots,u_k}=\Vect{v_1,\dots,v_{k+1}}\).

Ainsi, \(\paren{u_1,\dots,u_n}\) est une base orthogonale de \(E\).
\end{dem}

\begin{rem}
Si l'on souhaite obtenir une base orthonormée, on divise par les normes.
\end{rem}

On en déduit le théorème de la base orthonormée incomplète.

\begin{theo}
Soit \(E\) un espace euclidien.

Toute famille orthonormée de \(E\) peut être complétée en une base orthonormée de \(E\).
\end{theo}

\begin{exo}
Dans \(\R^n\) muni du produit scalaire canonique, on pose \(u=\paren{1,\dots,n}\).

Complétez la famille \(u\) en une base orthonormée de \(\R^n\).
\end{exo}

\begin{corr}~\\
\(\begin{matrix}
1 & 2 & 0 & \dots & 0 \\
2 & -1 & 0 &  & \vdots \\
\vdots & 0 & 4 &  & \vdots \\
\vdots & \vdots & -3 &  & \vdots \\
\vdots & \vdots & 0 &  & 0 \\
\vdots & \vdots & \vdots &  & n \\
n & 0 & 0 & \dots & n-1
\end{matrix}\) puis Gram-Schmidt.
\end{corr}

\subsection{Calculs en base orthonormée}

Soient \(E\) un espace euclidien et \(\fami{B}=\paren{e_1,\dots,e_n}\) une base orthonormée de \(E\).

Soient \(x,y\in E\), de coordonnées \(X=\tcoords{x_1}{\vdots}{x_n}_{\fami{B}}\) et \(Y=\tcoords{y_1}{\vdots}{y_n}_{\fami{B}}\).

Alors \[\ps{x}{y}=\sum_{i=1}^nx_iy_i=\trans{X}Y\qquad\norme{x}=\sqrt{\sum_{i=1}^nx_i^2}=\sqrt{\trans{X}X}\qquad\quantifs{\forall i\in\interventierii{1}{n}}x_i=\ps{x}{e_i}.\]

\begin{dem}
On a \[\begin{WithArrows}
\ps{x}{y}&=\sum_{i=1}^nx_i\ps{e_i}{y} \\
&=\sum_{i=1}^nx_i\sum_{j=1}^ny_j\ps{e_i}{e_j} \\
&=\sum_{1\leq i,j\leq n}x_iy_j\ps{e_i}{e_j} \Arrow{\(\ps{e_i}{e_j}=\delta_{i,j}\) car \(\fami{B}\) est orthonormée} \\
&=\sum_{i=1}^nx_iy_i.
\end{WithArrows}\]

De même, on a \(\ps{x}{e_j}=\sum_{i=1}^nx_i\ps{e_i}{e_j}=x_j\).
\end{dem}

\section{Sous-espaces orthogonaux}

\subsection{Orthogonalité de deux sous-espaces vectoriels}

\begin{defi}
Soient \(E\) un espace préhilbertien, \(F,G\) deux sous-espaces vectoriels de \(E\) et \(u\in E\).

On dit que \(u\) est orthogonal (ou normal) à \(F\) quand \(u\) est orthogonal à tous les vecteurs de \(F\).

On dit que \(F\) et \(G\) sont orthogonaux quand tout vecteur de \(F\) et tout vecteur de \(G\) sont orthogonaux, autrement dit quand \[\quantifs{\tpt\paren{x,y}\in F\times G}\ps{x}{y}=0.\]
\end{defi}

\begin{prop}
Si \(F\) est de dimension finie et a pour famille génératrice \(\paren{v_1,\dots,v_k}\), alors \(u\) est orthogonal à \(F\) ssi \(\quantifs{\tpt i\in\interventierii{1}{k}}\ps{u}{v_i}=0\).
\end{prop}

\begin{prop}
Si \(F\) et \(G\) sont orthogonaux, alors ils sont en somme directe : \(F\inter G=\accol{0}\).
\end{prop}

\begin{dem}
Supposons \(F\perp G\).

Soit \(x\in F\inter G\).

Comme \(x\in F\) et \(x\in G\), on a \(x\perp x\) \ie \(\ps{x}{x}=0\) \ie \(x=0\).

D'où \(F\inter G=\accol{0}\).

On peut généraliser à \(k\) sous-espaces vectoriels deux à deux orthogonaux \(F_1,\dots,F_k\).

Soit \(\paren{x_1,\dots,x_k}\in F_1\times\dots\times F_k\) tel que \(x_1+\dots+x_k=0\).

Pour \(i\in\interventierii{1}{k}\), on a \[\begin{aligned}
\ps{x_1+\dots+x_k}{x_i}&=\ps{x_1}{x_i}+\dots+\ps{x_k}{x_i} \\
&=\ps{x_i}{x_i} \\
&=0.
\end{aligned}\]

Donc \(x_i=0\).

Donc \(F_1,\dots,F_k\) sont en somme directe orthogonale.
\end{dem}

\subsection{Orthogonal d'un sous-espace vectoriel}

\begin{defi}
Soient \(E\) un espace préhilbertien et \(F\) un sous-espace vectoriel de \(E\).

On note \(F\ortho\) l'ensemble des vecteurs normaux à \(F\) : \[F\ortho=\accol{v\in E\tq\quantifs{\forall x\in F}\ps{v}{x}=0}.\]
\end{defi}

Avec cette notation, on a clairement l'équivalence : \[F\text{ et }G\text{ sont orthogonaux}\ssi F\subset G\ortho\text{ ou, ce qui revient au même, }G\subset F\ortho.\]

\begin{theo}
Soient \(E\) un espace préhilbertien et \(F\) un sous-espace vectoriel de \(E\).

Alors \(F\ortho\) est un sous-espace vectoriel de \(E\), orthogonal à \(F\) et donc en somme directe avec \(F\).
\end{theo}

\begin{dem}
Pour \(x\in E\), on pose \(\fonction{\phi_x}{E}{\R}{y}{\ps{x}{y}}\)

Pour \(x\not=0\), on a \(\phi_x\not=0\) (car \(\phi_x\paren{x}=\ps{x}{x}=\norme{x}^2>0\)).

Alors \[\begin{aligned}
F\ortho&=\accol{v\in E\tq\quantifs{\forall x\in F}\ps{x}{v}=0} \\
&=\accol{v\in E\tq\quantifs{\forall x\in F}v\in\ker\phi_x} \\
&=\biginter_{x\in F}\ker\phi_x.
\end{aligned}\]

Donc \(F\ortho\) est un sous-espace vectoriel de \(E\).

De plus, par définition de \(F\ortho\), on a \(\quantifs{\forall x\in F;\forall y\in F\ortho}\ps{x}{y}=0\).

Donc \(F\) et \(F\ortho\) sont orthogonaux (et donc en somme directe).
\end{dem}

\begin{prop}
Soient \(E\) un espace préhilbertien et \(F\) un sous-espace vectoriel de \(E\).

Alors \(F\subset\paren{F\ortho}\ortho\).
\end{prop}

\begin{rem}
En général, \(F\ortho\) n'est pas supplémentaire à \(F\) et \(F\) n'est pas égal à \(\paren{F\ortho}\ortho\).
\end{rem}

\begin{rem}
Dans le cas où \(F\) est une droite vectorielle dirigée par un vecteur \(u\), on note plutôt \(G=u\ortho\) l'orthogonal de \(F\). Dans ce cas, \(u\ortho\) est un hyperplan et on dit alors que \(u\) est un vecteur normal à \(G\).
\end{rem}

\begin{exo}
Montrez que si \(F\) est un sous-espace vectoriel de \(E\), alors \(\conj{F}\) est un sous-espace vectoriel de \(E\), que \(F\ortho=\conj{F}\ortho\) et que \(F\ortho\) est fermé.
\end{exo}

\section{Projection orthogonale sur un sous-espace vectoriel de dimension finie}

\subsection{Projection orthogonale}

\begin{defi}
Soient \(E\) un espace préhilbertien et \(F\) un sous-espace vectoriel de \(E\) de dimension finie.

Alors \(F\ortho\) est un supplémentaire de \(F\), appelé le supplémentaire orthogonal de \(F\).

Le projecteur sur \(F\) parallèlement à \(F\ortho\) est appelé le projecteur orthogonal sur \(F\).

La symétrie orthogonale par rapport à \(F\) est la symétrie par rapport à \(F\) parallèlement à \(F\ortho\).
\end{defi}

Si on connaît une base orthonormée \(\paren{e_1,\dots,e_p}\) de \(F\), alors il est facile de calculer la projection orthogonale de \(x\) sur \(F\) : \[p_F\paren{x}=\sum_{i=1}^p\ps{x}{e_i}e_i.\]

\begin{dem}
On a \(\dim F=p\).

\(F\) possède une base orthonormée \(\fami{B}=\paren{e_1,\dots,e_p}\).

Soit \(x\in E\). On cherche \(y\in F\) tel que \(x-y\perp F\).

\analyse

Si \(y\) existe alors \(y\in F=\Vect{e_1,\dots,e_p}\) donc \(y=\sum_{i=1}^py_ie_i\).

On a \(x-y\perp F\) donc pour \(j\in\interventierii{1}{p}\), \(x-y\perp e_j\), \ie \[\begin{aligned}
\ps{x-y}{e_j}&=0 \\
\ps{x}{e_j}-\ps{y}{e_j}&=0 \\
\ps{x}{e_j}-y_j&=0 \\
y_j&=\ps{x}{e_j}.
\end{aligned}\]

L'analyse prouve l'unicité de \(y\).

\synthese

On pose \(y=\sum_{i=1}^p\underbrace{\ps{x}{e_i}}_{y_i}e_i\).

On a \(y\in\Vect{e_1,\dots,e_p}=F\).

Pour \(j\in\interventierii{1}{p}\), on a \[\begin{aligned}
\ps{x-y}{e_j}&=\ps{x}{e_j}-\ps{y}{e_j} \\
&=\ps{x}{e_j}-y_j \\
&=0.
\end{aligned}\]

Donc \(x-y\perp F\).

\conclusion

On a montré \[\quantifs{\forall x\in E;\exists!y\in F}x-y\in F\ortho\] \ie \[\quantifs{\forall x\in E;\exists!\paren{y,z}\in F\times F\ortho}x=y+z\] \ie \[E=F\operp F\ortho.\]
\end{dem}

On en déduit l'inégalité de Bessel.

\begin{prop}
Soient \(E\) un espace préhilbertien et \(F\) un sous-espace vectoriel de \(E\) de dimension finie.

Si \(p\) est le projecteur orthogonal sur \(F\), alors \(\quantifs{\tpt x\in E}\norme{p\paren{x}}\leq\norme{x}\).
\end{prop}

\begin{dem}
Soit \(x\in E\).

On pose \(y=p_F\paren{x}\).

On a \(x-y\perp F\) donc \(x-y\perp y\) donc \[\begin{WithArrows}
\norme{x}^2&=\norme{\paren{x-y}+y}^2 \Arrow{Pythagore} \\
&=\norme{x-y}^2+\norme{y}^2 \\
&\geq\norme{y}^2.
\end{WithArrows}\]

D'où \(\quantifs{\forall x\in E}\norme{p_F\paren{x}}\leq\norme{x}\).

NB : on en déduit que \(p_F\) est continu.
\end{dem}

\subsection{Distance à un sous-espace vectoriel}

\begin{prop}
Soient \(E\) un espace préhilbertien, \(F\) un sous-espace vectoriel de \(E\) de dimension finie et \(x\in E\).

Soit \(y\) la projection orthogonale de \(x\) sur \(F\).

\(\quantifs{\Tpt z\in F}\norme{x-y}\leq\norme{x-z}\), avec égalité ssi \(z=y\).
\end{prop}

Autrement dit, le projeté orthogonal de \(x\) sur \(F\) est l'unique vecteur de \(F\) qui minimise la distance entre \(x\) et un point de \(F\).

\(\norme{x-y}\) est appelé la distance de \(x\) à \(F\), c'est la plus petite des distances entre \(x\) et un élément de \(F\), notée \(d\paren{x,F}\).

\begin{dem}
Pour \(z\in F\), \(z-y\in F\) et \(y-x\in F\ortho\) donc \(z-y\perp y-x\), donc \[\begin{WithArrows}
\norme{z-x}^2&=\norme{\paren{z-y}+\paren{y-x}}^2 \Arrow{Pythagore} \\
&=\norme{z-y}^2+\norme{y-x}^2 \\
&\geq\norme{y-x}^2.
\end{WithArrows}\]

Si \(\paren{e_1,\dots,e_p}\) est une base orthonormée de \(F\), on a \(y=\sum_{i=1}^p\ps{x}{e_i}e_i\).

De plus, on a \(\norme{x}^2=\norme{y}^2+\norme{x-y}^2\) donc \(\norme{x-y}^2=\norme{x}^2-\norme{y}^2\).

Or \(\norme{y}^2=\sum_{i=1}^p\ps{x}{e_i}^2\).

Donc \(d\paren{x,F}=\norme{x-y}=\sqrt{\norme{x}^2-\sum_{i=1}^p\ps{x}{e_i}^2}\).
\end{dem}

\begin{rem}
Tout ce qui précède est évidemment valable si \(E\) est de dimension finie.

Dans ce cas, pour tout sous-espace vectoriel \(F\) de \(E\), \(F\ortho\) est un supplémentaire de \(F\) dans \(E\).

Par conséquent, \(\dim F\ortho=\dim E-\dim F\).
\end{rem}
